\documentclass{article}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage[linewidth=1pt]{mdframed}
\usepackage[colorlinks]{hyperref}

\usepackage{verbatim}

\usepackage{algorithm}
\usepackage{algpseudocode}

\hypersetup{citecolor=DeepPink4}
\hypersetup{linkcolor=DarkRed}
\hypersetup{urlcolor=blue}

\usepackage{cleveref}

\setlength{\parindent}{1em}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1.0}

\begin{document}

\begin{titlepage}
	\centering
	{\scshape\LARGE Assignment 7\par}
	\vspace{1cm}
	{\scshape\Large Algorithms \& Complexity (CIS 522-01)\par}
	\vspace{1.5cm}
	{\Large\itshape Javier Arechalde\par}
	\vfill
	{\large \today\par}
\end{titlepage}

\section*{1. PC Manufacturer}

\subsection*{Problem model}

In this problem, we are a consulting company that works for a company that manufactures PC equipment. This company will have a projected supply for each week $S = [s_1,s_2,...,s_n]$. To deliver each weeks supply we can choose between two different carriers. One of them charges $r$ per pound of supply. Another one has a fixed rate $c$ per week, but if we choose this carrier we will have to choose for $4$ consecutive weeks. We will have to find the best combination possible of carriers to pay the least money possible.

Input:

\begin{itemize}
 \item Price per pound on Carrier 1: $r$
 \item Price per week on Carrier 2: $c$
 \item Projected supply for each week: $S$
\end{itemize} 

Output:

\begin{itemize}
 \item The optimal schedule: $Sch$
\end{itemize} 

\subsection*{Class}

This algorithm belongs to \textit{P} algorithms, as it is a decision problem that can be easily implemented in polynomial time.

\subsection*{Algorithm}

At the beginning of our algorithm, we will start by only choosing company A, until we reach week 4, once we reach week 4, we will start checking  what is more expensive, if choosing company A for the past 3 weeks and that week, or choosing the flat rate of company B. In case using company B is the better choice, we will update the best cost for that week with the best cost four weeks ago plus the flat rate multiplied by the four weeks. Otherwise we will add the cost per pound multiplied for the projected supply for that week to the previous week best cost.

In the end, we will have an array containing the best cost possible for each of the weeks, and the schedule.

\subsection*{Pseudocode}

\begin{algorithm}[H]
\caption{Carrier Selection Pseudocode}
\begin{algorithmic}[1]
\State We set $Cost_0 = 0$
\For{$i$ in range $0 \to n$}
 \If{$i<3$}
  \State $Cost_i = Cost_{i-1}+s_i*r$
 \Else
  \If{$Cost_{i-1}+s_i*r>4*c$}
   \State $Cost_i = Cost_{i-4}+4*c$
  \Else
   \State $Cost_i = Cost_{i-1}+s_i*r$
  \EndIf
 \EndIf
\EndFor
\State \Return Best cost possible $Cost_n$
\end{algorithmic}
\end{algorithm}

\subsection*{Implementation}

An example of how this algorithm works can be seen by running \textit{Problem1.py}

\subsection*{Time complexity}

The running time of our implementation will be $O(n)$, as we have to go through the $n$ weeks to find the lowest cost possible to deliver our product supply.

\section*{2. Processes scheduling}

\subsection*{Problem Model}

In this problem, we have $n$ processes on a system, each one of them being capable of running multiple jobs concurrently. Some jobs can't be scheduled at the same time because they both may need the same resource. We want to schedule in the next $k$ steps of the system all the jobs to run in at least one of the processes.

\subsection*{Class}

This problem belongs to the \textit{NP-Complete} class of problems, as it can be recognized as a partitioning problem, in which we have to divide in this case the jobs into different subsets, the processes, in a way that each one of the jobs appears in exactly one of the processes. More specifically, we can relate this problem to the graph coloring problem, as there exist conflicts between some of the jobs.

\subsection*{Complexity of the problem}

We will follow the following strategy to prove thato our problem is NP-Complete.

\begin{itemize}
 \item Prove that $X\in NP$
 \item Choose a problem $Y$ that is known to be NP-Complete
 \item Probe that $Y\leq_p X$
\end{itemize}

For our given problem, the certifier $B$ will prove that all the jobs are scheduled in at least one process, and at the same time that not two jobs are scheduled at the same time.

Then we choose a problem $Y$, in this case the graph coloring problem, that we know that is NP-Complete.

In the case of graph coloring, we have $k$ colors, and a Graph $G$, we want to find out if there is a possible k-coloring for that graph. There is also conflicts between objects, which means that conflicting objects can't go into the same set.

In the case of our problem, we have $n$ processes, and $k$ steps of the system. We want to schedule the different jobs in our system to run in at least one of the processes, while there is also conflicts between our jobs, because some of them need the same resource, so they can't run at the same time.

So we can relate the colors to the number of steps in our problem, so if we can color the grap with $k$ colors, we can also schedule the processes in $k$ steps of the system. And also the incompatibilities between some objects that can't go into the same set can be seen as the incompatibilities between two jobs that can't be scheduled at the same time because they need to access the same resource.

\section*{3. Database analysis}

In this case, we have two databases, each one of them containing $n$ values, we assume that not two values are the same. We want to find the median of this $2n$ values, using the mimimum number of queries as possible. To find this value, we will have to access the data in the databases. By specifying $k$ to a database, this database will return the $k^{th}$ smallest value.

\subsection*{Class}

This problem belongs to the \textit{P} class, as it can be easily implemented in Polynomial time.

\subsection*{Problem Model}

We will name each one of the databases $D_1$ and $D_2$, each one of these databases contains $n$ values, and the query $D_i(k)$ will return the $k^{th}$ smallest value in that database. We will also have two iterators $c_1$ and $c_2$, each one of them for one of the available databases we have.

\subsection*{Algorithm}

What our algorithm will do is iterate through the two databases, we will first compare the lowest values of both databases, if the lowest value is in the first database, we will increase the counter of the first database, else we will increase the other counter. We will continue to compare values, until we do $n+1$ comparisons. Whenever we reach the $(n+1)^{th}$ comparison, the value resulting from that comparison plus the value from the last comparison divided by $2$ will be the median, as we have an even number of values $2n$.

\subsection*{Pseudocode}

\begin{algorithm}[H]
\caption{Carrier Selection Pseudocode}
\begin{algorithmic}[1]
\State We initiallize $c_1 = c_2 = 0$
\State We initiallize $val_n = val_{n1} = 0$
\For{$i$ in range $0 \to n+1$}
 \State $val_1 = D_1(c_1)$
 \State $val_2 = D_2(c_2)$
 \State $val_n = val_{n1}$
 \If{$val_1>val_2$}
  \State $val_{n1} = val_1$
  \State $c_1 = c_1 + 1$
 \Else
  \State $val_{n1} = val_2$
  \State $c_2 = c_2 + 1$
 \EndIf
\EndFor
\State \Return $median = (val_n+val_{n1})/2$
\end{algorithmic}
\end{algorithm}

\subsection*{Implementation}

An example of how this algorithm works can be seen by running \textit{Problem3.py}

\subsection*{Time Complexity}

This algorithm can find the median of the values in the two databases in $O(n)$ time, as it only needs to compare $n+1$ values from the two databases.

\section*{4. Photocopying Service}

\subsection*{Problem Model}

In this problem we will have different customers, each one of them having a job that takes $t_i$ to complete. Also, each one of these jobs has a weight $w_i$ that is the importance of that customer to the business.

We want to find the order of jobs that minimizes the weigthed sum of the completion times: $\sum{i=1}{n}w_i C_i$.

Input:
\begin{itemize}
 \item List of the time that takes to complete each client's job: $T = [t_1,t_2,...,t_n]$
 \item List of the weight for each client's job: $W = [w_1,w_2,...,w_n]$
\end{itemize}

Output
\begin{itemize}
 \item List containing the optimal order of jobs: $Schedule = [job_x,job_y,...]$ 
\end{itemize}

\subsection*{Class}

This problem belongs to \textit{P}, as it can be solved in polynomial time. We will prove this later on.

\subsection*{Algorithm}

We will solve this problem using a greedy approach, first we will sort the jobs by decreasing weight $w_i$ using quicksort algorithm, then we will schedule this jobs, starting by the ones that have higher $w_i$ first. This way, we can minimize the weighted sum of completion times.

\subsection*{Pseudocode}

\begin{algorithm}[H]
\caption{Job scheduling}
\begin{algorithmic}[1]
\State First we sort the jobs by weight using QuickSort
\Function{Quicksort}{array}
 \If{Array length is $1$}

  \Return array
 \EndIf
 \If{Array length $ > 1$}
  \State $pivot == array[0]$
  \For{Element in array}
   \If{$element<pivot$}
    \State We add the element to the lowerlist
   \EndIf
   \If{$element>pivot$}
    \State We add element to the upperlist
   \EndIf
   \If{d}
    \State Append element to the pivotlist
   \EndIf
  \EndFor
  \State upperlist = \Call{quicksort}{upperlist}
  \State lowerlist = \Call{quicksort}{lowerlist}
 \EndIf
 \State Return lowerlist + pivotlist + upperlist
\EndFunction
\State
\State Now we will start scheduling the jobs by decreasing weight order
\State We initialize start time of jobs: $s_{job} = 0$
\While{We didn't schedule all jobs}
 \State Get the timings for the corresponding job
 \State
 \State Job start and finish
 \State $s_{job} = f_{previous job}$
 \State $f_{job} = s_{job} + t_{i}$
 \State
 \State We return the start and finish time for each one of the jobs

\EndWhile
\end{algorithmic}
\end{algorithm}

\subsection*{Implementation}

An example of how this algorithm works can be seen by running \textit{Problem4.py}

\subsection*{Time Complexity}

The time complexity of the scheduling part of the algorithm is $O(n)$, as we only need to go through the list once to schedule the jobs, but prior to this we need to sort our jobs by using quicksort algorithm, which has a time complexity of $O(n\log n)$. Then, as $O(n\log n)$ is upper bound of $O(n)$, the time complexity of our implementation will be $O(n\log n)$.

\section*{5. Communication network}

\subsection*{Problem model}

In this problem, we have a communication network, modeled as a directed grapg $G = (V,E)$, a source node $s$ and a sink node $t$. There are $c$ users that want to make use of this network. Each one of these users will reserve a specific path $P_i$ that goes from $s$ to $t$, and we have the following restriction: if two users $i$ and $j$ request a path $P_i$ and $P_j$, then $P_i$ and $P_j$ cannot share any edges.

We want to be able to accomodate as many users as possible from $c$ to use the communication network, following the given prerequisite. 

What we will do is to model the communication network as the directed graph $G$, and give all the edges a capacity of $1$, this way, we can reduce the problem to a problem of finding the maximum flow. Then if the maximum flow equals $c$, we can accomodate all the users on the network, otherwise the network capacity is not sufficient.

\subsection*{Class}

The \textit{Ford-Fulkerson} algorithm for finding the maximum flow in a directed graph can be implemented in Polynomial time, so this problem belongs to $P$.

\subsection*{Time Complexity}

The \textit{Ford-Fulkerson} algorithm can be used to find a maximum flow in our directed graph in $O(mn)$ time as we dont have any duplicate edges in our graph, and each edge has unit capacity. 
Where $m$ is the number of edges, and $n$ is the number of nodes.

\section*{6. Project selection}

In this problem we are a student in the end of the semester, and we have $n$ final projects. Each one of these projects will give us some points for our final performance. Also, some of these projects have prerequisites, which means that we can only work on that project if we completed the prerequisite projects first. Our goal is to select a set of projects that will maximize the utility points we get.

\subsection*{Problem model}

We will model this problem as a network-flow problem.

In this case, the nodes will be the different projects, and each one of these projects will have associated to it the points that we can get from each of this project. Then for each one of the prerequisites for a project, we will create and edge that goes from that project to the prerequisite project. We won't assign any capacities for the edges just yet.

Then we will model this problem, as the project selection problem. We will start by adding a source $s$ and a sink $t$. Then for each project that has positive points, we will create and edge that goes from the source, and the node representing that project,this edge having the number of points as its capacity. For each project that has negative points, we will create and edge that goes from that node to the sink, that edge having the capacity equal to that number of points. For the preexisting edges, we will set their capacity to $\infty$, which means that that edge has no upper bound.

Then, we will find the maximum number of points that we can achieve by working on different projects, by finding the minimum cut of the graph, by using \textit{Ford-Fulkerson} algorithm.

\subsection*{Class}

This problem can be reduced to a problem of finding the maximum flow in a graph, then it can be solved using \textit{Ford-Fulkerson} algorithm which can be implemented in Polynomial time, so this problem belongs to $P$.


\subsection*{Time complexity}

The time complexity of this algorithm will be $O(mn)$, as its based on \textit{Ford-Fulkerson} algorithm. Where $m$ is the number of edges, that will be equal to all the prerequisites plus the number of projects, and $n$ will be the number of nodes, that in this case will be the number of projects plus the source node, and the sink node.

\section*{7. Summer sports camp}

In this problem, we are helping organize a summer sports camp. The camp needs to hire at least one counselor who is skilled at each of the $n$ sports the camp offers. They have applications from $m$ potential counselors, for each of the $n$ sports, a subset of the $m$ applicants is qualified in that sport. We want to find out if we will be able to hire a number of counselors $k<m$, and have at least one counselor qualified in each one of the $n$ sports. 

\subsection*{Problem model}

We will model this problem as bipartite matching problem, in which we will have two sets, $X$, and $Y$. We first will model the graph as a bipartite graph $G$, which is an undirected graph, which has the property that every edge, has one end in $X$, and the other one in $Y$.

Then we will construct a flow network $G'$ from $G$. First we will direct all edges in $G$ from $X$ to $Y$. Then we will create a source, and add one edge for every node in $X$ that goes from source $s$ to that node. After that, we will create a sink $t$, and for every node in $Y$ we will ad an edge that goes from $Y$ to $t$. In the end, we will give each edge in $G'$ a capacity of 1.

Then we will compute the maximum flow in $G'$, and the maximum flow, will equal the maximum matching in $G$.

\subsection*{Class}

The \textit{Ford-Fulkerson} algorithm for finding the maximum matching in a bipartite graph can be implemented in Polynomial time, so this problem belongs to $P$.

\subsection*{Time complexity}

The \textit{Ford-Fulkerson} algorithm can be used to find a maximum matching in a bipartite graph in $O(mn)$ time, where $m$ is the number of edges, and $n$ is the number of nodes, in this case the number of nodes will be the number of counselors plus the number of sports offered in the camp and the source and sink node, and the number of edges will be equal or less to the number of counselors multiplied to the number of nodes plus the number of counselors and the number of sports.

\end{document}
